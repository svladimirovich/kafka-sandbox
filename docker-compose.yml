version: "3.2"

# Manual creation with Docker (default values for ARGS are used)
### 1) Zookeeper:
# docker run -d -p 2181:2181 --network kafka-net --network-alias zookeeper kafka-cluster/zookeeper
### 2) Kafka:
# docker run -d -p 9092:9092 --network kafka-net --network-alias kafka kafka-cluster/kafka
### 3) Kafka Connect:
# docker run -d -p 8083:8083 --network kafka-net --network-alias connect kafka-cluster/connect

services:
  zookeeper:
    # image: kafka-cluster/zookeeper
    build:
      context: ./Zookeeper
      dockerfile: Dockerfile
    ports:
      - 2181:2181
    # networks:
    #   kafka-net:
    #     aliases:
    #       - zookeeper

  kafka:
    # image: kafka-cluster/kafka
    build:
      context: ./Kafka
      dockerfile: Dockerfile
      args:
        ZOOKEEPER_HOST: zookeeper
        # https://rmoff.net/2018/08/02/kafka-listeners-explained/
        # kafka-connect will contact broker using this advertised host name
        # and any client that connects to kafka should find kafka broker under this host name
        # best thing I could come up with for now is to define 'kafka' to point to localhost in /etc/hosts file
        # that way you get kafka-connect working within the docker network, and any client on your dev host
        KAFKA_ADVERTISED_HOST: kafka
    ports:
      - 9092:9092
    # networks:
    #   kafka-net:
    #     aliases:
    #       - kafka
    depends_on:
      - zookeeper

  kafka-favorite-color:
    build:
      context: ./java/favorite-color-stream
      dockerfile: Dockerfile
    depends_on:
      - kafka

  kafka-word-count:
    build:
      context: ./java/word-count-stream
      dockerfile: Dockerfile
    depends_on:
      - kafka

  kafka-connect:
    # image: kafka-cluster/connect
    build:
      context: ./Kafka-Connect
      dockerfile: Dockerfile
      args:
        BOOTSTRAP_SERVERS_LIST: kafka:9092
        REST_PORT: 8083
    ports:
      - 8083:8083
    # networks:
    #   kafka-net:
    #     aliases:
    #       - connect
    depends_on:
      - kafka

  # if elasticsearch fails to start with an error message like this:
  # ERROR: [1] bootstrap checks failed
  #        [1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
  # Run the following command to increase memory on the Docker HOST:
  # $ sysctl -w vm.max_map_count=262144
  # elasticsearch:
  #   image: elasticsearch:6.5.1
  #   ports:
  #     - 9200:9200
  #     #- 9300:9300

# networks:
#   kafka-net:
#     #external: true
#     driver: bridge